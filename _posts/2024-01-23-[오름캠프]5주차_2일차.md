---
title: "[오름캠프]5주차_2일차"
date: 2024-01-23
---

# 1.강의 중 배운 내용 요약  

1. 초빙 강사님의 생성형 AI 관련 특강
2. [무작정 머신러닝 해보기](https://colab.research.google.com/drive/1geBJovmz124MxiaWsYjLxwYv-Ae9ko35?usp=sharing)
3. [머신러닝 회귀](https://colab.research.google.com/drive/1Cdyk5DQubbsHK6WNiGUJXUKy1ztINNF3?usp=sharing)

# 2. 새로 알게된 내용

<details close>
<summary>접기/펼치기</summary>
<div markdown="1">

금일은 컨디션 난조로 코드 따라가기도 바빠서 강사님의 설명을 놓친 게 많다.
그런 관계로 내용을 큰 흐름으로 정리하도록 하겠다.

1. 일반적인 머신러닝 절차

    - 설명 : 머신러닝의 절차는 넓게보면 더 다양할 수 있지만 일반적인 경우, 
             데이터가 수집이 되었다는 전제하에 진행하게 된다. 그럼 데이터분석가는 크게 데이터 전처리, 학습 및 예측, 평가 및 튜닝을 진행하게 된다. 

    - 전처리 : 데이터분석가는 데이터를 분석 즉 처리하기 전에, 데이터를 분석에 알맞게 정제해야한다. 이를 전처리(Preprocessing)이라고 한다. 전처리는 다음과 같은 과정으로 진행된다. 
        
        1. 데이터 불러오기 
            - 우선적으로 데이터를 불러온다. 
        2. 데이터 확인
            - 데이터를 정제하기 위해서는 데이터가 어떻게 되어있는지 부터 알아야한다. 
            - 이를 위해 데이터프레임의 통계적 요약 정보, 상위/하위 5개 결과, 결측치 존재 여부 등을 확인한다. 
        3. 데이터 전처리 
            - 분석에 쓸모없는 칼럼(불필요한 특성) 제거, 분석을 위한 데이터 변형(보통 원본을 유지하는 선에서 진행), 결측치 치환 또는 제거이다.
       
        
    - 학습 및 예측 : 정제가 된 데이터를 이용해서 학습 및 예측을 진행한다. 이를 위해서 크게 데이터 분할, 학습, 예측을 순차적으로 진행하며 과정은 다음과 같다.
        
        1. 데이터 분할 
            - 여기서 분할할 데이터를 보통 데이터셋이라고 부른다.
            - 이 데이터셋은 학습용 Training과 예측용 Test로 분할된다. 
            - 여기서 Training sets은 또 Training과 Validation(검증)으로 분할될 수 있는 데, Validation은 모델의 하이퍼파라미터 미세 조정을 위해 쓰이기 때문에 여기에서 다루는 일반적인 절차에서는 제외한다. 
            - 데이터 분할을 할 때는 일반적으로 train:test = 8:2 비율로 분할한다. 실험을 통해서 그 비율이 수정되긴 하지만, 기존 결과가 주어지지 않은 상태에서 base로 설정하기에는 적합한 비율이다.
            - 데이터 분할에서 유의할 점은 random_state 옵션을 사용해서 고정된 값으로 분할되게 해야하는 것이다. 
            - 이는 추후 튜닝을 해야하기 때문이다. 설명을 하자면 random_state이 고정되지 않으면 정말 데이터가 랜덤하게 분할되기 때문에, 매번 돌릴 때마다 다른 결과가 나오게 된다. 그럼 튜닝은 무슨 기준으로 해야할지 정할 수가 없어진다. 그럼 주사위 던지기 마냥 원하는 값이 나올 때까지 반복해서 그제서야 튜닝을 하게되는 불상사가 발생할 수 있다.
            - 두번째는 재현 때문이다. 예를 들어, 본인이 논문을 써서 결과가 이렇게 나왔어요하고 결과를 보여줬다고 가정해보자. 그럼 그 논문이 가치가 있다면, 다른 사람이 그 논문의 코드를 수정하고 코드를 더해서 더 나은 모델을 만들 수도 있다. 그런데 이때, random_state가 없다면 논문에서 보여줬던 그 결과가 나오지 않아서 결과가 재현되지 않고, 이 때문에 다른 사람이 그 코드를 활용하기 어려워진다.

        2. 학습 
            - 초기 학습할 때는 기준이 될만한 베이스라인 모델을 선정해야한다. 
            - 금일 수업에서는 앙상블 알고리즘의 한 종류인 랜덤포레스트를 base 모델로 사용했다.
            - 랜덤포레스트를 간단히 설명하자면 콘테스트에서 n명의 심사원 각각 참가자에 대해 평가점수를 매기는 데, 이 평가점수들을 평균낸 것이라고 할 수 있다. 
            - 그럼 평균값을 가지고 의사결정으로 바로 적용할 수 있을까? 답은 No다. 
            - 현실에서 대입해 생각해보자. 심사원들은 정말 다양하다. 분석적이거나 감성적이거나 점수를 박하게 주거나 후하게 주거나 제각각이다. 
            - 그럼 여기서 평균의 함정을 알 수 있다. 만일 심사원들이 7명은 점수를 아주 높게 주었고, 3명은 점수를 아주 낮게 줬다고 가정해보자. 그럼 여기서 평균값은 평가점수들을 대표할 수 가 없다.
            - 결국 평균값은 참고로 사용되며, 실제로는 class A에서는 어떻게 나왔고, class B에서는 어떻게 나와서 등등의 설명이 필요하게 된다. 

        3. 예측
            - test set을 대상으로 예측을 한다.
        

    - 평가 및 튜닝 : 학습 결과와 예측 결과를 평가하고 평가 결과의 피드백으로 튜닝을 진행하여 모델의 성능을 개선한다. 과정은 다음과 같다.
        
        1. 평가
            - 학습의 결과를 실제값이라고 한다면 test set을 대상으로 예측한 것을 예측값이라고 부른다.
            - 그렇다면 여기서 평가는 예측값이 과연 얼마나 실제값과 일치하는 지를 평가하는 것이다.
            - 흔히 사용하는 비교로 모의고사(train set)를 잘 치뤘으면 실제 시험(test set)에서도 잘 치르는 지 확인하는 것이다. 그렇게 함으로써 이 모델이 범용적으로 쓸만한 것인가를 알 수 있는 것이다.
            - 결국 train set, test set 모두 잘 맞추는 게 적합한 모델인 것이다.
            - 문제는 과대적합 또는 과소적합이 발생할 수 있는 것이다.
            - 이 둘은 가끔 들으면 혼동될 수 있는 개념이라 학습과 과대적합을 기준으로 정리하고 과소적합은 그 반대격으로 생각하면 된다.
            - 먼저 과대적합은 학습은 정말 잘 되었는 데, 테스트에서 형편없이 나온 것이다. 즉, 학습이 과하게 되었다고 보면된다. 모의고사는 만점인데, 실전이 형편없는 셈이라는 것이다.
            - 그럼 과소적합은 그 반대로 학습에서 형편없는 데, 테스트에서 결과가 잘 나온 것이다.
            현실로 치면 모의고사는 잘 못 보는 학생이 실제시험에서 점수가 높게 나온 거라 볼 수 있다. 정말 실전에 강한 학생일지는 모르겠지만 높은 확률로 컨닝을 했던가 운이 아주 좋았을 수 있다고 볼 수 있다. 그렇다면 이 학생은 모범생(적합한 모델)로 보기는 어려울 것이다.

        2. 튜닝
            - 평가 결과가 맘에 안 들면 EDA로 다시 돌아가 처음부터 진행하고 시각화를 통해 어떤 속성(feature; 데이터 프레임의 열)이 중요한지 파악할 수 있다. 하지만 결과가 나쁘지 않다면 바로 모델 튜닝을 진행할 수 있다.
            - 모델을 튜닝한다는 것은 모델의 하이퍼파라미터를 최적화하는 것이다.
            - 구체적으로는 분류 또는 회귀 알고리즘에서 가장 적합한 하이퍼파라미터를 설정하는 것이다.
            - 그렇다면 가장 적합한 하이퍼파라미터를 찾기 위해 역시 라이브러리의 도움을 받아야한다.
            - 금일 코드에서는 GridSearchCV를 사용했으며, 이는 사용한 알고리즘에 가장 적합한 하이퍼파라미터를 찾아준다.
            - 물론 여러가지 설정을 해주어야 한다만, 일일이 손으로 여러 번 수정하며 돌리는 것에 비하면 편한 수준이다.

회귀 부분부터는 컨디션이 좋지 않아 정리를 잘 못했다. 그나마 중요한 기억에 남는 부분이 있었다면, 오즈비를 계산해서  ROC에 대한 근거를 설명하는 게 중요하다는 점과 TPR과 FPR을 근거로 결과를 설명할 줄도 알아야한다는 점이다. 그 외 기타 중요한 내용들은 다른 분들이 정리해줄 것이라 생각한다.

</div>
</details>


# 3. 기억에 남는 주요 실습 내용

회귀분석에서 히스토그램 분석과 상관관계를 나타내는 히트맵을 분석한 내용이 기억에 남았다.

# 4. 수업 중 궁금했던 내용
오늘은 궁금한 게 없었다. 

# 5. 내일을 위한 다짐
1. github 1일 1 commit하자.
2. 컨디션 관리하자.

# 6. 참고 템플릿

<details close>
<summary>접기/펼치기</summary>
<div markdown="1">
    
    [오늘 강의 요약 정리] - 오늘 어떤 것을 배웠나요?

    [오늘의 발견] - 오늘 배웠던 것 중에 처음 알았던 것은 어떤 것이 있었나요?

    [오늘의 실습] - 실습때 했던 코드를 첨부하는 것을 추천드립니다.

    [오늘의 질문] - 이해가 가지 않았다던가? 추가적으로 궁금한 것을 정리해보세요.

    [오늘의 복습] - 남은 시간 동안 어떻게 복습할 것인지?

    [내일을 위한 다짐] - 개인적인 피드백을 적어보고, 중간에 마음이 꺾이지 않기 위해 나의 다짐을 적어보고, 오늘을 정리해봅시다.

</div>
</details>
