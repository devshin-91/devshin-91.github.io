---
title: "[오름캠프]5주차_3일차"
date: 2024-01-24
---

# 1.강의 중 배운 내용 요약  

1. 초빙 강사님의 생성형 AI 관련 특강
2. [머신러닝 - 리마인드, 트리모델과 앙상블](https://colab.research.google.com/drive/1OmPWMWvZvnMfWcgoKNtlaee9TpD_LVYH?usp=sharing)
3. [딥러닝 - 텐서플로 기초, 실습, automl](https://colab.research.google.com/drive/12BV1tcwbRHQLEEchYWDo-IYNajiX-P97?usp=sharing)

# 2. 새로 알게된 내용

<details close>
<summary>접기/펼치기</summary>
<div markdown="1">

1. 회귀문제를 분류처럼 사용하는 방법
    : 회귀 -> 분류 0원 ~ 5천만원 -> 집값이 낮다 / 5천 ~ 1억 집값 높다. -> 분류

    ```python
    ## 6.5점을 기준으로 좋은 와인과 나쁜 와인을 구분하겠다고 선언
    bins = (2, 6.5, 8)
    group_names = ['bad', 'good']
    wine['quality'] = pd.cut(wine['quality'], bins = bins, labels = group_names)

    ## Good/Bad는 인식할 수 없음. 따라서 이를 인식할 수 있도록 Label Encoding을 실시

    label_quality = LabelEncoder()
    wine['quality'] = label_quality.fit_transform(wine['quality'])
    ```

2. 독립변수와 종속변수 분할 및 학습

    ```python
    ##종속변수와 독립변수를 나누어주는 작업
    x = wine.drop('quality', axis = 1)
    y = wine['quality']

    ## 변수별로 Train과 Test 쓸 데이터 셋을 분류x
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)


    ## 측정 지표의 표준화.
    sc = StandardScaler()
    x_train = sc.fit_transform(x_train)
    x_test = sc.fit_transform(x_test)
    ```

    ```python
    ## 로지스틱 회귀
    model = LogisticRegression()
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    print(classification_report(y_test, y_pred))

    print("Accuracy:", metrics.accuracy_score(y_test, y_pred))
    print("Precision:", metrics.precision_score(y_test, y_pred))
    print("Recall:", metrics.recall_score(y_test, y_pred))
    ```

    ```python
    ## SVC
    model_svc = SVC()
    model_svc.fit(x_train, y_train)
    y_pred_svc = model_svc.predict(x_test)
    print(classification_report(y_test, y_pred_svc))

    print("Accuracy:", metrics.accuracy_score(y_test, y_pred_svc))
    print("Precision:", metrics.precision_score(y_test, y_pred_svc))
    print("Recall:", metrics.recall_score(y_test, y_pred_svc))

    # 결과적으로 보면 어떤 알고리즘이든 사용되는 과정은 같다. 
    # 1. 알고리즘 불러오기
    # 2. fit
    # 3. 예측
    # 4. 리포트 내기

    # 그렇다면 여러 알고리즘을 비교할 때 이 과정을 전부 자동화하면 어떨까?
    ```

3. 결정트리(DecisionTree)

    - 기본형태 : 결정트리의 구조는 if, else 논리로 결정이 가지가 쳐진 나무형태이다.

    - 구성 : 규칙 노드, 리프 노드, 서브 트리

    - 유의점 : 데이터 양이 많으면 분석하기 좋으나 너무 많은 결정 트리 가지는 과적합을 잃으킨다.

    - 결정트리 읽는 순서 : 조건, 불순도, 총 샘플 수, 클래스 별 샘플 수

    - 여기서 주목해야할 부분은 불순도이다. 정확히는 지니 불순도이다.

    - 지니불순도 = 1- (타겟이 아닌 클래스[음성 클래스(label 값 = 0), 나쁜 와인] 비율의 제곱 + 타겟 클래스[양성 클래스(label 값 = 1), 좋은 와인] 비율의 제곱)

    - 이 지니 분순도를 통해 가지치기가 진행된다.

4. 앙상블 

    - 설명 : 다굴 앞에서는 장사가 없다는 말이 있다. 앙상블이 딱 그런 거라고 생각하면된다. 여러 알고리즘을 이용해서 성능이 좋은 한 알고리즘보다 더 좋은 성능을 낸다.

    - 앙상블의 종류 : 보팅, 배깅, 부스팅

        - 보팅 : 투표(기준: 다수결 또는 가중치) => 투표 많이 받은 것을 기준으로 계산

        - 배깅 : 결정트리를 여러 개 만듬. 즉, 각기 다른 전략을 가진 결정 트리 여러 개가 서로 전략을 합쳐서 최종 결론을 내림.

        - 부스팅 : 오답노트 이용과 같음. 즉, 틀린 부부만 가지고 학습하여 오류를 줄임.

        - 스태킹(일단 어렵고 잘 안 쓰여 내용 포함 x)

5. 텐서플로

    - 설명
        - 딥러닝 프레임워크 중 하나인 tensorflow는 그 이름같이 입력을 텐서로 받는다. 
        - 내부에는 keras도 들어있어서 keras를 통해 쉽게 모델의 층을 쌓을 수 있다.
        - 모델에 옵션을 넣는 것도 compile 시 입력형태에 맞게 loss 옵션과 optimizer를 잘 고르면 돼서 편리하다.
        - 그 이후는 학습, 평가의 과정을 거친다.
        - 단, 프레임워크를 이용하다보니 그 과정에서 사용되는 코드가 간결하다.
    
6. 정규화(Normalization)
    - 설명
        - 딥러닝 기초 문제를 다루다보면 굳이 입력받은 데이터를 255로 나누는 걸 볼 수 있다. 
        - 아 이미지 데이터에는 그냥 255를 나누는 거구나 할 수 있는 데, 그게 아니다.
        - 일단 컴퓨터의 연산을 생각해보자. 컴퓨터는 0,1 이라는 이진연산을 한다. 그렇기 때문에 컴퓨터에게 적절한 범위란 0~1사이인 것이다.
        - 그런데, 이미지의 각 픽셀이 가질 수 있는 rgb의 값을 보니 그 범위가 0~255다.
        - 저 범위의 값을 그대로 넣으면 컴퓨터에겐 너무 범위가 넓게 된다.
        - 그렇기에 rgb의 최대값이 255라는 점을 근거로 입력된 값에 255를 나누면 그 범위는 0~1사이로 좁혀진다.
    - 필요성
        - 현실로 치면 화살 과녁의 가장자리를 맞추다 점차 중앙을 맞추는 컴퓨터에게 범위가 최소로 맞춰진 과녁을 주는 셈이다. 그렇다면 기존 과녁보다 훨씬 작은 과녁에서 중앙을 금방 맞출 수 있을 것이다.
        - 앞에서 언급한 손실함수를 이용해 설명해도 마찬가지라 볼 수 있다.
        - 딥러닝 모델의 학습이란 최소의 손실(실제값과 예측갑의 오차)값을 갖게 하는 최적의 값을 찾는 과정이다. 이 과정에서 손실함수와 옵티마이저를 통해 손실이 최저가 되는 지점에 수렴해가는 데, 정규화가 되지 않은 데이터에서는 그 범위가 너무 넓어서 최저점에 수렴해가는 시간이 굉장히 길다. 화살을 쏘면 무조건 맞추긴 하는 데, 과녁 바깥에서 과녁 중앙에 수렴하는 시간이 그 범위만큼 오래걸린다는 거다.
        - 물론 손실을 최저로 만드는 학습시간을 줄이기 위해 학습률을 높일 수는 있으나, 과도한 학습률 증가는 발산으로 이루어질 수 있다. 사람마냥 집중력이 떨어져 과녁 바깥을 맞추게 되는 것이다.  
        - 반면, 정규화를 하면 그 범위는 0~1 사이가 되므로, 손실함수가 최저점에 훨씬 빠르게 수렴하게 된다. 그러다 보니 학습률을 크게 건드리지 않고도 학습을 안정적으로 진행시킬 수 있다.

8. AutoMl
    - 설명
        - 방금 텐서플로 같은 딥러닝 프레임워크로 딥러닝 모델을 평가까지 완료했다고 가정하자.
        - 그런데 방금 사용한 모델이 최고일 수는 없기 때문에 결국 이 모델 저 모델을 돌리게 된다.
        - 이 반복이 필요한 작업을 자동화할 수 없을까하는 고민이 생기게 되는 데, 이 고민을 automl이 해결해준다.
        - 딥러닝도 머신러닝과 마찬가지로 사소해보이는 하이퍼파라미터 하나로도 성능 향상의 여지가 있기 때문에 사람은 이것까지 직접 손을 봐야한다. 하지만 automl은 이것까지 대신해준다.
        - 최소한의 설정으로 할 수 있는 비교는 automl이 다 해주는 것이다.
    - 유의점
        - automl이 실무에도 쓰인다고 하지만, 역시 맹신할 수는 없기 때문에 참고용으로 주로 쓰인다고 한다.
        
9. EDA와 딥러닝 프레임워크의 필요성
    - 설명
        - automl이 이렇게도 편하면 왜 앞에서 EDA도 직접해보고 텐서플로도 직접 다 써보는 고생을 했을까?
        - 일단 EDA의 경우 컴퓨터가 사람처럼 되기 전까지는 사람만이 할 수 있기 때문이다. 
        - Good Input Good Output이라는 말이 있듯이 데이터를 좋게 만들어줘야 좋은 결과가 나올 수 있다. 그러려면 EDA는 반드시 필요하다.
        - 그리고 보통 수집된 데이터들은 캐글이나 이런 곳에 올라오는 그런 정제된 데이터가 아닌 더럽다 싶을정도로 손을 많이 봐야하는 경우도 있다.
        - 그 다음으로 딥러닝 프레임워크의 경우에는 현재 존재하고 있는 모델만으로는 한계가 있어서 모델을 수정하거나 새로 모델을 만들어야 할 필요가 있기에 직접 써봐야 한다. 그리고 만일 유행하는 딥러닝 모델이 있다면 그 모델을 빠르게 이해하고 구현해서 서비스에 접목시킬 필요가 있다. 이를 위해 필요한 최소한의 조건이 딥러닝 프레임워크에 대한 이해이다.

</div>
</details>


# 3. 기억에 남는 주요 실습 내용

automl 내용이 기억에 남았다.

# 4. 수업 중 궁금했던 내용
오늘은 궁금한 게 없었다. 

# 5. 내일을 위한 다짐
1. github 1일 1 commit하자.

# 6. 참고 템플릿

<details close>
<summary>접기/펼치기</summary>
<div markdown="1">
    
    [오늘 강의 요약 정리] - 오늘 어떤 것을 배웠나요?

    [오늘의 발견] - 오늘 배웠던 것 중에 처음 알았던 것은 어떤 것이 있었나요?

    [오늘의 실습] - 실습때 했던 코드를 첨부하는 것을 추천드립니다.

    [오늘의 질문] - 이해가 가지 않았다던가? 추가적으로 궁금한 것을 정리해보세요.

    [오늘의 복습] - 남은 시간 동안 어떻게 복습할 것인지?

    [내일을 위한 다짐] - 개인적인 피드백을 적어보고, 중간에 마음이 꺾이지 않기 위해 나의 다짐을 적어보고, 오늘을 정리해봅시다.

</div>
</details>
